{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QuantumSim - Computational Improvements\n",
    "\n",
    "Author: Wouter Pennings<br>\n",
    "Date: April 2025\n",
    "\n",
    "This notebook outlines proposed improvements to the modeling approach used in QuantumSim.\n",
    "\n",
    "It focuses on addressing two primary issues:\n",
    "- Memory limitations\n",
    "- Poor performance\n",
    "\n",
    "Summary of proposed changes to QuantumSim:\n",
    "- Use of sparse matrices and efficient algorithm implementations\n",
    "- Integration of native code via JIT (Just-In-Time) compilation\n",
    "- Hardware acceleration using GPUs\n",
    "- Caching and memoization techniques\n",
    "- Lazy generation of matrices\n",
    "- Minor additional enhancements, such as:\n",
    "  - Switching the state vector to a row-based format\n",
    "\n",
    "These changes aim to significantly improve the performance of QuantumSim while maintaining the same number of qubits. They also open the door to simulating a greater number of qubits—potentially a dozen or more.\n",
    "\n",
    "Toward the end of this notebook, performance and output comparisons will be made between this improved version and the current implementation of QuantumSim.\n",
    "\n",
    "The full implementation with all proposed improvements can be found in [quantumsim_performante.py](quantumsim_performante.py).\n",
    "\n",
    "Note: The implementations presented here are not necessarily optimized. Their purpose is to demonstrate that such improvements can effectively address the identified issues. This enhanced version of QuantumSim builds upon the minimal implementation introduced in [QuantumSimIntroduction.ipynb](QuantumSimIntroduction.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] Cupy could not be imported, make sure that your have installed Cupy\n",
      "\tIf you do not have a NVIDIA GPU, you cannot install Cupy\n",
      "\tQuantumsim will still work accordingly, just less performant\n",
      "\t > Installation guide: https://docs.cupy.dev/en/stable/install.html\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import math\n",
    "import cmath\n",
    "import time\n",
    "from typing import List, Union, Tuple\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "from numba import njit\n",
    "try:\n",
    "    import cupy\n",
    "    import cupyx.scipy.sparse as cupysparse\n",
    "    GPU_AVAILABLE = True\n",
    "except:\n",
    "    print(\"[ERROR] Cupy could not be imported, make sure that your have installed Cupy\")\n",
    "    print(\"\\tIf you do not have a NVIDIA GPU, you cannot install Cupy\")\n",
    "    print(\"\\tQuantumsim will still work accordingly, just less performant\")\n",
    "    print(\"\\t > Installation guide: https://docs.cupy.dev/en/stable/install.html\")\n",
    "    GPU_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inherit quantum computer simulation problem\n",
    "\n",
    "Each additional qubit that a quantum computer/circuit has doubles its computing power, this \"property\" of quantum computers is what makes them exponentially faster than classical computers. However, it is also the reason why they are difficult to simulate, because each additional qubit requires your computer to be twice as powerful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computationally heavy operations\n",
    "\n",
    "There are two main (mathematical) operations inside of Quantumsim which combined take up the vast majority of the computational time. They are discussed below.\n",
    "\n",
    "### Kronecker product\n",
    "Kronecker product is used to build the unitary operation matrices. The time complexity of the function is $O(4^n)$, which means that every additional qubit, makes it four times slower. Building a unitary operation matrix takes roughly 20 seconds \n",
    "\n",
    "All the kronecker operations combined, take roughly 20 seconds for one operation in a fifteen qubits circuit. The kronecker product can be found in `CircuitUnitaryOperation.get_combined_operation_for_qubit` and `CircuitUnitaryOperation.get_combined_operation_for_cnot`\n",
    "\n",
    "```python\n",
    "def get_combined_operation_for_qubit(operation:np.ndarray, q:int, N:int):\n",
    "    identity = QubitUnitaryOperation.get_identity()\n",
    "    combined_operation = np.eye(1,1)\n",
    "\n",
    "    for i in range(0, N):\n",
    "        if i == q:\n",
    "            combined_operation = np.kron(combined_operation, operation)\n",
    "        else:\n",
    "            combined_operation = np.kron(combined_operation, identity)\n",
    "\n",
    "    return combined_operation\n",
    "```\n",
    "\n",
    "### Matrix-vector multiplication\n",
    "\n",
    "Matrix-vector multiplication is use to \"execute\" the unitary operation matrices on the `Statevector`. The time complexity of the matrix-vector multiplication is $O(N^2)$. Matrix-vector multiplication between a operation and the statevector in a 15 qubit system takes around four second. The multiplication can be found in `Statevector.apply_unitary_operation`  \n",
    "\n",
    "The `apply_unitary_operation` also has a check whether the operation is a unitary matrix \n",
    "\n",
    "```python\n",
    "def apply_unitary_operation(self, operation):\n",
    "    # Check if operation is a unitary matrix\n",
    "    if not np.allclose(np.eye(2**self.N), np.conj(operation.T) @ operation):\n",
    "        raise ValueError(\"Input matrix is not unitary\")\n",
    "    \n",
    "    self.state_vector = operation @ self.state_vector\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory limitations\n",
    "\n",
    "An a regular 16 GB system there currently is a ceiling of 14 qubits. The unitary matrices (operations) have a space complexity of $O(4^n)$, meaning that every additional qubit quadruples the size of the unitary matrices. \n",
    "\n",
    "Amount of elements in a unitary matrix from 14 qubit circuit:\n",
    "\n",
    "$(2^{14})^2 = 268,435,456\\ elements$\n",
    "\n",
    "Every elements uses 128 bits or 16 bytes, as it is a complex numbers of with the real and imaginary part both are 64 bit floats.\n",
    "\n",
    "$268,435,456 * 16 = 4,294,967,296\\ bytes$\n",
    "\n",
    "If we do the same calculations for a 15 qubit system, we can see that we are already out of memory in a 16 GB system. These are the elements and bytes for a 15 qubit system:\n",
    "\n",
    "$(2^{15})^2 = 1,073,741,824\\ elements$\n",
    "\n",
    "$1,073,741,824 * 16 = 17,179,869,184\\ bytes$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proposed Changes & Improvements\n",
    "\n",
    "### Sparse matrix (COO)\n",
    "\n",
    "Unitary operation matrices are mostly sparse, meaning that most elements in the matrix are zero. **Sparsity** refers to the percentage of **non-zero (NNZ) elements** in the matrix. As the number of qubits in a quantum circuit increases, the corresponding operation matrices grow larger and become increasingly sparse.  \n",
    "\n",
    "The sparsity of a matrix is defined as the percentage of NNZ elements relative to the total number of elements in the matrix.  \n",
    "\n",
    "For example, consider a **10×10** matrix with **7 non-zero elements (NNZ)**. The sparsity is calculated as follows:  \n",
    "\n",
    "$$\n",
    "\\text{sparsity} = 100 \\times \\left( \\frac{\\text{NNZ}}{\\text{total elements}} \\right) = 100 \\times \\left( \\frac{7}{10 \\times 10} \\right) = 100 \\times 0.07 = 7\\%\n",
    "$$\n",
    "\n",
    "To store these unitary matrices more efficiently by exploiting the sparsity of them. They are converted to a [sparse matrix](https://en.wikipedia.org/wiki/Sparse_matrix), these are special data structures to store sparse matrices very efficiently. There are many different types, but COO (Coordinate list) was chosen for Quantumsim. Taking a Kronecker product using the COO format is computationally extremely efficient, much better then E.G. CSR (Compressed sparse row)\n",
    "\n",
    "The sparsity of a **Hadamard operation matrix** (the least sparse unitary matrix) can be determined using the following formula, where $n$ represents the number of qubits in the circuit:  \n",
    "\n",
    "$$\n",
    "f(n) = 100 \\times \\left(\\frac{1}{2}\\right)^{(n-1)}\n",
    "$$\n",
    "\n",
    "Additionally, the amount of memory required to store a **Hadamard operation matrix** for $n$ qubits can be estimated using these formulas:  \n",
    "\n",
    "- **Dense matrix:** $f(n) = 4^n \\times 16$\n",
    "- **Sparse (COO) matrix:** $f(n) = 96 \\times 2^{(n-1)}$\n",
    "\n",
    "One thing to keep in mind is that once the circuit exceeds a certain number of qubits, the unitary operation matrices cannot be converted back to dense matrices because they will be larger than the amount of memory available. This specific number of qubits depends on the system, but is generally between 13 and 16 qubits. This means that all algorithms and functions involving a unitary operation matrix should be implemented to support sparse matrices instead of dense matrices; requiring a rewrite of a large part of the entire simulation.\n",
    "\n",
    "**Scipy** provides sparse matrix functionality, data structures and functions, to work with (COO) sparse matrices.\n",
    "\n",
    "The `Circuit` class changes from this dense implementation:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "class Circuit:\n",
    "    \"\"\"\n",
    "    Class representing a quantum circuit of N qubits.\n",
    "    \"\"\"\n",
    "    def __init__(self, N):\n",
    "        self.qubits = N\n",
    "        self.state_vector = StateVector(self.qubits)\n",
    "        self.quantum_states = [self.state_vector.get_quantum_state()]\n",
    "        # Circuit.operations contains the unitary operation matrices in a dense (regular) form\n",
    "        self.operations: list[np.ndarray] = [] \n",
    "        self.descriptions = []\n",
    "```\n",
    "\n",
    "to this sparse matrix implementation:\n",
    "\n",
    "```python\n",
    "import scipy as sc\n",
    "\n",
    "class Circuit:\n",
    "    \"\"\"\n",
    "    Class representing a quantum circuit of N qubits.\n",
    "    \"\"\"\n",
    "    def __init__(self, N, use_lazy=False, use_cache=False, use_GPU=False):\n",
    "        self.N = N\n",
    "        self.state_vector = StateVector(self.N)\n",
    "        self.quantum_states = [self.state_vector.get_quantum_state()]\n",
    "        # Circuit.operations contains the unitary operation matrices in a sparse COO matrix\n",
    "        # Data structure is provided by SciPy\n",
    "        self.operations: list[sc.sparse.coo_matrix] = []\n",
    "        self.descriptions = []\n",
    "```\n",
    "\n",
    "### Sparse matrix algorithms\n",
    "\n",
    "Now that the operation matrices have been converted to sparse COO matrices, all algorithms involved have to be updated too. In addition to making the simulation work again but many possibility of many more qubits, the algorithms will also be much faster. Optimized mathematical operations such as, multiplications, transpose and kronecker, on sparse matrices are much faster than on dense matrices. The greater the sparsity greater the performance improvements.\n",
    "\n",
    "Kronecker product and matrix-vector multiplication are the only two algoriths which will need to be converted for the COO format. Why they are used in QuantumSim can be found earlier in the notebook. Scipy already provides a sparse implementation for kronecker product; [scipy.sparse.kron(A, B)](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.kron.html). This implementation from SciPy is used in QuantumSim, but will be slightly altered to make it work. Because the \"base\" unitary operation matrices are 2x2, the SciPy implementation converts them to dense matrices, but that is not what is most optimal. They have probably done this for performance reasons, but in our specific case that will not work. Below you find the altered SciPy kronecker implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/scipy/scipy/blob/v1.15.1/scipy/sparse/_construct.py#L458\n",
    "# Docs: https://docs.scipy.org/doc/scipy-1.15.1/reference/generated/scipy.sparse.kron.html\n",
    "def coo_kron(A:sparse.coo_matrix, B:sparse.coo_matrix) -> sparse.coo_matrix:\n",
    "    output_shape = (A.shape[0] * B.shape[0], A.shape[1] * B.shape[1])\n",
    "\n",
    "    if A.nnz == 0 or B.nnz == 0:\n",
    "        # kronecker product is the zero matrix\n",
    "        return sparse.coo_matrix(output_shape)\n",
    "\n",
    "    # Expand entries of a into blocks\n",
    "    # When using more then 32 qubits, increase to int64\n",
    "    row = np.asarray(A.row, dtype=np.int32).repeat(B.nnz)\n",
    "    col = np.asarray(A.col, dtype=np.int32).repeat(B.nnz)\n",
    "    data = A.data.repeat(B.nnz)\n",
    "    \n",
    "    row *= B.shape[0]\n",
    "    col *= B.shape[1]\n",
    "\n",
    "    # increment block indices\n",
    "    row = row.reshape(-1, B.nnz)\n",
    "    row += B.row\n",
    "    row = row.reshape(-1)\n",
    "\n",
    "    col = col.reshape(-1, B.nnz)\n",
    "    col += B.col\n",
    "    col = col.reshape(-1)\n",
    "\n",
    "    # compute block entries\n",
    "    data = data.reshape(-1, B.nnz) * B.data\n",
    "    data = data.reshape(-1)\n",
    "\n",
    "    return sparse.coo_matrix((data, (row, col)), shape=output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix vector multiplication for a sparse matrix is not common for the COO format. You can either convert to a format such as CSC, which is much more common for multiplications, or you can convert from COO to CSC, which is a time-consuming and computationally intensive process. In practice, the performance penalty for using COO is not large, and therefore converting to a more optimal format for multiplication is not worthwhile. \n",
    "\n",
    "The implementation for sparse matrix vector multiplication can be found below, it is not based on an existing implementation and is made for a column vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coo_spmv_column(rowIdx:np.ndarray[np.int32], \n",
    "                    colIdx:np.ndarray[np.int32], \n",
    "                    values:np.ndarray[np.complex128], \n",
    "                    v:np.ndarray[np.complex128]) -> np.ndarray[np.complex128]:\n",
    "    \"\"\"\n",
    "    Performs sparse matrix-vector (column based) multiplication using COO format.\n",
    "    \"\"\"\n",
    "    out = np.zeros((len(v), 1), dtype=values.dtype)  # Initialize output vector\n",
    "    nnz = len(values)  # Number of nonzero elements\n",
    "\n",
    "    for i in range(nnz):  # Iterate over nonzero elements\n",
    "        out[rowIdx[i], 0] += values[i] * v[colIdx[i], 0]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def coo_spmv_row(rowIdx, colIdx, values, v):\n",
    "    \"\"\"\n",
    "    Performs sparse matrix-vector (row based) multiplication using COO format.\n",
    "    \n",
    "    Parameters:\n",
    "    - rowIdx (list[int]): Row indices of nonzero elements.\n",
    "    - colIdx (list[int]): Column indices of nonzero elements.\n",
    "    - values (list[float]): Nonzero values of the matrix.\n",
    "    - v (numpy array): Dense vector for multiplication.\n",
    "    \n",
    "    Returns:\n",
    "    - numpy array: Result vector y = A * v\n",
    "    \"\"\"\n",
    "    out = np.zeros(len(v), dtype=values.dtype)  # Initialize output vector\n",
    "    nnz = len(values)  # Number of nonzero elements\n",
    "\n",
    "    for i in range(nnz):  # Iterate over nonzero elements\n",
    "        out[rowIdx[i]] += values[i] * v[colIdx[i]]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coo_kron(A, B):\n",
    "    output_shape = (A.shape[0] * B.shape[0], A.shape[1] * B.shape[1])\n",
    "\n",
    "    if A.nnz == 0 or B.nnz == 0:\n",
    "        # kronecker product is the zero matrix\n",
    "        return sparse.coo_sparse(output_shape)\n",
    "\n",
    "    # Expand entries of a into blocks\n",
    "    # When using more then 32 qubits, increase to int64\n",
    "    row = np.asarray(A.row, dtype=np.int32).repeat(B.nnz)\n",
    "    col = np.asarray(A.col, dtype=np.int32).repeat(B.nnz)\n",
    "    data = A.data.repeat(B.nnz)\n",
    "\n",
    "    row *= B.shape[0]\n",
    "    col *= B.shape[1]\n",
    "\n",
    "    # increment block indices\n",
    "    row = row.reshape(-1,B.nnz)\n",
    "    row += B.row\n",
    "    row = row.reshape(-1)\n",
    "\n",
    "    col = col.reshape(-1,B.nnz)\n",
    "    col += B.col\n",
    "    col = col.reshape(-1)\n",
    "\n",
    "    # compute block entries\n",
    "    data = data.reshape(-1,B.nnz) * B.data\n",
    "    data = data.reshape(-1)\n",
    "\n",
    "    return sparse.coo_sparse((data, (row, col)), shape=output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coo_kron_gpu(A:cupysparse.coo_matrix, B:cupysparse.coo_matrix):\n",
    "    out_shape = (A.shape[0] * B.shape[0], A.shape[1] * B.shape[1])\n",
    "\n",
    "    if A.nnz == 0 or B.nnz == 0:\n",
    "        # kronecker product is the zero matrix\n",
    "        return cupysparse.coo_matrix(out_shape).asformat(format)\n",
    "\n",
    "    # expand entries of A into blocks\n",
    "    row = A.row.astype(cupy.int32, copy=True) * B.shape[0]\n",
    "    row = row.repeat(B.nnz)\n",
    "    col = A.col.astype(cupy.int32, copy=True) * B.shape[1]\n",
    "    col = col.repeat(B.nnz)\n",
    "    data = A.data.repeat(B.nnz) \n",
    "\n",
    "    # increment block indices\n",
    "    row = row.reshape(-1, B.nnz)\n",
    "    row += B.row\n",
    "    row = row.ravel()\n",
    "\n",
    "    col = col.reshape(-1, B.nnz)\n",
    "    col += B.col\n",
    "    col = col.ravel()\n",
    "\n",
    "    # compute block entries\n",
    "    data = data.reshape(-1, B.nnz) * B.data\n",
    "    data = data.ravel()\n",
    "\n",
    "    return cupysparse.coo_matrix((data, (row, col)), shape=out_shape).asformat(format)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future improvements\n",
    "\n",
    "1. **Lazy evaluation and caching**: Lazely generated matrices could still be cached. Currently not possible as it is one of the two.\n",
    "2. **Use disk for caching**: Especially if matrices are too big.\n",
    "3. **For extremly large matrices could be processed in blocks, while rest is on disk**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
